# SAiLL AI Engine - Production Dependencies

# Core AI and ML libraries
torch>=2.0.0,<3.0.0              # PyTorch for local Llama inference
transformers>=4.30.0,<5.0.0      # Hugging Face transformers for model loading
tokenizers>=0.13.3,<1.0.0        # Fast tokenizers for text processing
accelerate>=0.20.0,<1.0.0        # Hugging Face acceleration utilities
bitsandbytes>=0.41.0,<1.0.0      # Memory optimization for large models

# OpenAI integration
openai>=1.0.0,<2.0.0             # Official OpenAI Python client

# Web and API frameworks
fastapi>=0.100.0,<1.0.0          # High-performance API framework
uvicorn[standard]>=0.23.0,<1.0.0 # ASGI server for FastAPI
pydantic>=2.0.0,<3.0.0           # Data validation and settings

# Database and caching
asyncpg>=0.28.0,<1.0.0           # Async PostgreSQL driver
redis>=4.5.0,<6.0.0              # Redis client for caching
sqlalchemy>=2.0.0,<3.0.0         # SQL toolkit and ORM

# Audio processing (for future voice integration)
librosa>=0.10.0,<1.0.0           # Audio analysis
soundfile>=0.12.0,<1.0.0         # Audio file I/O
numpy>=1.24.0,<2.0.0             # Numerical computing

# Monitoring and observability
prometheus-client>=0.17.0,<1.0.0 # Prometheus metrics
structlog>=23.0.0,<24.0.0        # Structured logging

# HTTP and networking
httpx>=0.24.0,<1.0.0             # Async HTTP client
websockets>=11.0.0,<12.0.0       # WebSocket support

# Utilities and helpers
python-dotenv>=1.0.0,<2.0.0      # Environment variable loading
click>=8.1.0,<9.0.0              # Command line interface
rich>=13.0.0,<14.0.0             # Rich text and beautiful formatting
typer>=0.9.0,<1.0.0              # CLI framework built on click

# Development and testing dependencies
pytest>=7.4.0,<8.0.0             # Testing framework
pytest-asyncio>=0.21.0,<1.0.0    # Async test support
pytest-cov>=4.1.0,<5.0.0         # Coverage reporting
black>=23.0.0,<24.0.0             # Code formatting
isort>=5.12.0,<6.0.0             # Import sorting
flake8>=6.0.0,<7.0.0             # Linting
mypy>=1.5.0,<2.0.0               # Type checking

# Optional GPU optimization (uncomment if using NVIDIA GPUs)
# nvidia-cublas-cu11>=11.10.3.66   # CUDA BLAS library
# nvidia-cuda-runtime-cu11>=11.7.99 # CUDA runtime
# nvidia-cudnn-cu11>=8.5.0.96       # CUDA Deep Neural Network library

# Production deployment
gunicorn>=21.0.0,<22.0.0          # WSGI HTTP Server for production
